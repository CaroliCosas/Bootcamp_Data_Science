{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7941abf",
   "metadata": {},
   "source": [
    "## Estadística Inferencial\n",
    "\n",
    "Se llama estadística inferencial a la rama de la Estadística encargada de hacer deducciones, es decir, inferir propiedades, conclusiones y tendencias, a partir de una muestra del conjunto. Su papel es interpretar, hacer proyecciones y comparaciones.\n",
    "\n",
    "- Correlaciones Lineales\n",
    "- Outliers\n",
    "    - Puntuación Z (Z-Score)\n",
    "    - Valle de Tukey\n",
    "- Contraste de Hipotesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e62b5-455d-4494-b483-bcbe817de050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Versiones\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\")\n",
    "print(f\"seaborn=={sns.__version__}\")\n",
    "print(f\"scipy=={scipy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9727c00-26a4-4389-9096-9b3fbd0112ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "# Estos datos representan: ENGINESIZE, FUELCONSUMPTION_CITY, CYLINDERS, CO2EMISSIONS del csv FuelConsumptionCo2\n",
    "\n",
    "with open(file = \"../Data/ENGINESIZE.pkl\", mode = \"br\") as file:\n",
    "    engine_size = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/FUELCONSUMPTION_CITY.pkl\", mode = \"br\") as file:\n",
    "    fuelconsumption_city = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/CYLINDERS.pkl\", mode = \"br\") as file:\n",
    "    cylinders = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/CO2EMISSIONS.pkl\", mode = \"br\") as file:\n",
    "    co2_emissions = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dccd99",
   "metadata": {},
   "source": [
    "### Correlación entre 2 variables\n",
    "\n",
    "La correlación entre dos variables es una medida que indica la fuerza y la dirección de la relación lineal entre ellas. También se puede entender como qué tan probable es que una variable cambie cuando la otra variable cambia.\n",
    "\n",
    "El método que se va a utilizar para calcular la correlación entre 2 variables es el **coeficiente de correlación lineal de Pearson**. El cual mide únicamente la relación entre ambas variables sin considerar dependencias y siempre buscando una correlación lineal. Se suele denotar con la letra griega _**rho**_ $\\rho$.\n",
    "\n",
    "Para poder calcular la correlación utilizamos el cálculo de la covarianza entre ambas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a187d79-473e-407b-abd1-4cf9b0eb0b1e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Large Cov(X, Y) = \\frac{\\sum_{i=1}^{n}(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{n}\\\\\n",
    "\\Large \\rho = \\frac{Cov(X, Y)}{\\sigma_{x}\\sigma_{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3be6aa",
   "metadata": {},
   "source": [
    "Donde el valor de $\\rho$ puede tomar valores desde -1 hasta +1 y de acuerdo a su valor se pueden asignar las siguientes categorías:\n",
    "\n",
    "- 0: asociación nula.\n",
    "- 土 0.1: asociación pequeña.\n",
    "- 土 0.3: asociación mediana.\n",
    "- 土 0.5: asociación moderada.\n",
    "- 土 0.7: asociación alta.\n",
    "- 土 0.9: asociación muy alta.\n",
    "\n",
    "Este estadístico, como muchos otros, suele venir con un valor $\\rho$ que representa su nivel de significancia. Esto lo veremos más en detalle en el contraste de hipótesis.\n",
    "\n",
    "Para calcular el **coeficiente de correlación lineal de Pearson** usaremos la función **stats.pearsonr()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59f583-32f3-40fd-a94d-ff5810f0bbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coeficiente de correlación lineal de Pearson\n",
    "# Variables engine_size y fuelconsumption_city\n",
    "\n",
    "stats.pearsonr(engine_size, fuelconsumption_city)\n",
    "\n",
    "# El primer valor es la correlación, el segundo su nivel de significacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c1e88-d311-4d20-805c-34bee746bf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para obtener el primer valor\n",
    "\n",
    "stats.pearsonr(engine_size, fuelconsumption_city)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99bfafb-1a19-47f5-9d8a-01480c7c2513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (engine_size)\n",
    "\n",
    "print(f\"Correlación engine_size/engine_size: {stats.pearsonr(engine_size, engine_size)[0]}\")\n",
    "print(f\"Correlación engine_size/fuelconsumption_city: {stats.pearsonr(engine_size, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlación engine_size/cylinders: {stats.pearsonr(engine_size, cylinders)[0]}\")\n",
    "print(f\"Correlación engine_size/co2_emissions: {stats.pearsonr(engine_size, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd45fb-6e25-4e15-8449-a1bc686b5cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (fuelconsumption_city)\n",
    "\n",
    "print(f\"Correlación fuelconsumption_city/engine_size: {stats.pearsonr(fuelconsumption_city, engine_size)[0]}\")\n",
    "print(f\"Correlación fuelconsumption_city/fuelconsumption_city: {stats.pearsonr(fuelconsumption_city, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlación fuelconsumption_city/cylinders: {stats.pearsonr(fuelconsumption_city, cylinders)[0]}\")\n",
    "print(f\"Correlación fuelconsumption_city/co2_emissions: {stats.pearsonr(fuelconsumption_city, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91253ff9-fd22-4b22-8d75-f92f7f6f788f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (cylinders)\n",
    "\n",
    "print(f\"Correlación cylinders/engine_size: {stats.pearsonr(cylinders, engine_size)[0]}\")\n",
    "print(f\"Correlación cylinders/fuelconsumption_city: {stats.pearsonr(cylinders, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlación cylinders/cylinders: {stats.pearsonr(cylinders, cylinders)[0]}\")\n",
    "print(f\"Correlación cylinders/co2_emissions: {stats.pearsonr(cylinders, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d7d4c-f5ba-4664-8d73-864f09af6c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (co2_emissions)\n",
    "\n",
    "print(f\"Correlación co2_emissions/engine_size: {stats.pearsonr(co2_emissions, engine_size)[0]}\")\n",
    "print(f\"Correlación co2_emissions/fuelconsumption_city: {stats.pearsonr(co2_emissions, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlación co2_emissions/cylinders: {stats.pearsonr(co2_emissions, cylinders)[0]}\")\n",
    "print(f\"Correlación co2_emissions/co2_emissions: {stats.pearsonr(co2_emissions, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2e2b-1608-4be3-8595-4e63fba328ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podriamos crear una matriz de correlaciones\n",
    "\n",
    "variables = [engine_size, fuelconsumption_city, cylinders, co2_emissions]\n",
    "\n",
    "matriz_corr = list()\n",
    "\n",
    "for variable1 in variables:\n",
    "    \n",
    "    fila = list()\n",
    "    \n",
    "    for variable2 in variables:\n",
    "        \n",
    "        fila.append(stats.pearsonr(variable1, variable2)[0])\n",
    "        \n",
    "    matriz_corr.append(fila)\n",
    "    \n",
    "np.array(matriz_corr)\n",
    "\n",
    "# Variables: engine_size, fuelconsumption_city, cylinders, co2_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648bad4",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Un outlier es un individuo de una población con **características/valores extremadamente atípicos**. Existen varios métodos para detectar outliers, pero los más comunes aprovechan las medidas de dispersión para conseguirlo.\n",
    "\n",
    "Un mismo individuo puede ser considerado como outlier por un método, y como normal por otro, por lo que debemos tener en cuenta cómo funcionan antes de aplicarlos.\n",
    "\n",
    "A continuación veremos cómo podemos usar las medidas de **rango intercuartil** (_ric_ o _iqr_) y **desviación estándar** (_std_) para detectar outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a018d",
   "metadata": {},
   "source": [
    "#### 1. Puntuación Z (_Z-Score_)\n",
    "La **puntuación z** es una medida que nos dice a qué distancia se encuentra un valor de la media en términos de desviación estándar. Si un valor tiene una **puntuación z** de -1, quiere decir se encuentra a una desviación estándar a la izquierda de la media. En otras palabras, ese valor es igual a la media menos la desviación estándar.\n",
    "\n",
    "Resulta que para distribuciones normales, los valores comprendidos entre **puntuaciones z** de -3 y 3 constituyen el 99,7% de todos los datos. Podemos aprovechar esto para declarar cualquier valor con una **puntuación z** fuera de ese rango como atípico.\n",
    "\n",
    "Esta forma de detectar outliers es la más sencilla de todas, pero pierde eficacia cuando se trata de distribuciones asimétricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una lista de números aleatorios con la librería random\n",
    "array = np.array([random.gauss(100, 15) for _ in range(10_000)])\n",
    "\n",
    "def outliers_z_score(array, z = 3):\n",
    "    \n",
    "    # Calculamos media y std\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    \n",
    "    # Calculamos los limites laterales (𝜇 ± z*𝜎)\n",
    "    lim_l = mean - z*std\n",
    "    lim_r = mean + z*std\n",
    "    \n",
    "    # Filtramos los elementos del array, los que esten fuera de los limites laterales.\n",
    "    outliers = [elem for elem in array if elem < lim_l or elem > lim_r]\n",
    "    \n",
    "    # Filtramos los elementos del array, los que no pertenezcan a outliers.\n",
    "    normal_data = [elem for elem in array if elem not in outliers]\n",
    "    \n",
    "    # Retornamos ambos arrays, uno con los datos sin outliers, otro con los outliers\n",
    "    return np.array(normal_data), np.array(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data, outliers = outliers_z_score(array)\n",
    "\n",
    "print(f\"Total de no-outliers: {len(normal_data)}\")\n",
    "print(f\"Total de outliers: {len(outliers)}\")\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(array)\n",
    "std = np.std(array)\n",
    "\n",
    "# Limites laterales\n",
    "lim_l = mean - 3*std\n",
    "lim_r = mean + 3*std\n",
    "\n",
    "# No-Outliers\n",
    "plt.hist(normal_data, bins = 50, color = \"blue\")\n",
    "\n",
    "# Outliers\n",
    "plt.hist(outliers, bins = 50, color = \"red\")\n",
    "\n",
    "# 𝜇 ± 3𝜎\n",
    "plt.axvline(lim_l, color = \"black\", linestyle = \"--\")\n",
    "plt.axvline(lim_r, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428624aa",
   "metadata": {},
   "source": [
    "#### 2. La valla de Tukey (_Tukey's Fence Rule_)\n",
    "Este método es algo más robusto ante distribuciones asimétricas que el anterior.\n",
    "\n",
    "Igual que con las **puntuaciones z**, necesitamos establecer unos límites a la izquierda y a la derecha de la distribución. Esta vez, vamos a aprovechar los cuantiles. Tomando como referencia los cuartiles **Q1** y **Q3**, nos alejamos $1.5*ric$ de cada uno de ellos a la izquierda y a la derecha, respectivamente. Esos serán nuestros puntos de corte. Cualquier valor que se encuentre fuera de ese rango, lo consideramos como atípico.\n",
    "\n",
    "Podemos modificar el multiplicador del rango intercuartil ($k=1.5$) a nuestro antojo, según necesitemos ser más o menos estrictos. Al incrementar el multiplicador, incrementamos el rango de normalidad, por lo que tendremos menos outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04154070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_tukey(array, k = 1.5):\n",
    "    \n",
    "    # Calculamos los cuartiles Q1 y Q3\n",
    "    q1 = np.quantile(array, 0.25)\n",
    "    q3 = np.quantile(array, 0.75)\n",
    "    \n",
    "    # Rango InterCuartil\n",
    "    ric = q3 - q1\n",
    "    \n",
    "    # Calculamos los límites laterales\n",
    "    lim_l = q1 - k*ric\n",
    "    lim_r = q3 + k*ric\n",
    "    \n",
    "    # Filtramos los elementos del array, los que esten fuera de los limites laterales.\n",
    "    outliers = [elem for elem in array if elem < lim_l or elem > lim_r]\n",
    "    \n",
    "    \n",
    "    # Filtramos los elementos del array, los que no pertenezcan a outliers.\n",
    "    normal_data = [elem for elem in array if elem not in outliers]\n",
    "    \n",
    "    # Retornamos ambos arrays, uno con los datos sin outliers, otro con los outliers\n",
    "    return np.array(normal_data), np.array(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data, outliers = outliers_tukey(array)\n",
    "\n",
    "print(f\"Total de no-outliers: {len(normal_data)}\")\n",
    "print(f\"Total de outliers: {len(outliers)}\")\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d28e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.quantile(array, 0.25)\n",
    "q3 = np.quantile(array, 0.75)\n",
    "ric = q3 - q1\n",
    "\n",
    "lim_l = q1 - 1.5*ric\n",
    "lim_r = q3 + 1.5*ric\n",
    "\n",
    "# No-Outliers\n",
    "plt.hist(normal_data, bins = 50, color = \"blue\")\n",
    "\n",
    "# Outliers\n",
    "plt.hist(outliers, bins = 50, color = \"red\")\n",
    "\n",
    "# Q1 - 1.5*ric\n",
    "plt.axvline(lim_l, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "# Q3 + 1.5*ric\n",
    "plt.axvline(lim_r, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56078086",
   "metadata": {},
   "source": [
    "Existen muchos otros métodos que aprovechan estadísticos como el **MAD (Median Absolute Deviation)**, o algoritmos de clustering como **DBSCAN** para detectar outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a109e4",
   "metadata": {},
   "source": [
    "### Contraste de hipótesis\n",
    "\n",
    "El contraste de hipótesis es una técnica de la estadística inferencial que nos permite tomar decisiones sobre afirmaciones o suposiciones acerca de una población, basadas en la información obtenida de una muestra de esa población.\n",
    "\n",
    "1. Para llevar a cabo un contraste de hipótesis necesitamos primero formular dos hipótesis. La primera se conoce como hipótesis nula ($H_0$), y es una suposición o afirmación de que la condición que queremos probar o refutar no es cierta. Por ejemplo, si queremos comprobar si el cociente intelectual promedio de los alumnos de cuarto de la ESO es diferente al cociente intelectual promedio de la población general, la hipótesis nula sería que son iguales, que no existe diferencia.\n",
    "\n",
    "    Por el contrario, tenemos también la hipótesis alternativa ($H_1$), que no es más que lo opuesto a la nula. En ese caso, la $H_1$ sería que el alumno promedio de cuarto de la ESO tiene un CI diferente (mayor o menor) que el el ciudadano promedio de España.\n",
    "\n",
    "    El contraste de hipótesis nos permite tomar una decision al respecto de estas dos hipótesis. Nos da cierta certeza para tomar una u otra como la verdadera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a3ea3",
   "metadata": {},
   "source": [
    "- Ejemplo\n",
    "    - $H_0$: las emisiones de CO2 de _**FORD**_ son en promedio **iguales** que las emisiones de CO2 de _**MERCEDES-BENZ**_.\n",
    "    - $H_1$: las emisiones de CO2 de _**FORD**_ son en promedio **diferentes** que las emisiones de CO2 de _**MERCEDES-BENZ**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb18d20-6465-42b3-8fea-71368a45c2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vamos a extraer muestras del csv FuelConsumptionCo2\n",
    "# Cada array representa una marca de coche y vamos a extraer las emisiones de CO2\n",
    "# Trabajaremos con 3 muestras, el primer ejemplo serán con las muestras 1 y 2\n",
    "# Se pueden hacer otros ejemplos con las muestras 1 y 3 o 2 y 3.\n",
    "\n",
    "# MAKE == \"FORD\"\n",
    "with open(file = \"../Data/muestra_1.pkl\", mode = \"br\") as file:\n",
    "    muestra_1 = pickle.load(file)\n",
    "\n",
    "# MAKE == \"MERCEDES-BENZ\"\n",
    "with open(file = \"../Data/muestra_2.pkl\", mode = \"br\") as file:\n",
    "    muestra_2 = pickle.load(file)\n",
    "\n",
    "# MAKE == \"CHEVROLET\"\n",
    "with open(file = \"../Data/muestra_3.pkl\", mode = \"br\") as file:\n",
    "    muestra_3 = pickle.load(file)\n",
    "\n",
    "print(f\"Datos FORD: {len(muestra_1)}\")\n",
    "print(f\"Datos MERCEDES-BENZ: {len(muestra_2)}\")\n",
    "print(f\"Datos CHEVROLET: {len(muestra_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180abc-f080-4e37-b615-d0431d3f187d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Veamos las distribuciones de los datos en una gráfica\n",
    "\n",
    "sns.kdeplot(muestra_1, color = \"magenta\", label = \"FORD\")\n",
    "sns.kdeplot(muestra_2, color = \"red\", label = \"MERCEDES-BENZ\")\n",
    "sns.kdeplot(muestra_3, color = \"blue\", label = \"CHEVROLET\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452e1bf",
   "metadata": {},
   "source": [
    "2. Esto lo conseguimos estableciendo un nivel de significancia. Es, en esencia, el nivel de confianza de los resultados del contraste. Se representa con la letra griega **alpha** $α$ y nos indica el valor máximo que aceptamos que tenga el valor $p$.\n",
    "    \n",
    "    Ahora, el valor $p$ representa una probabilidad. Concretamente es la probabilidad que tenemos de obtener una muestra como la que usamos en el contraste, dado que la hipótesis nula sea verdadera. En otras palabras, es un valor de confianza. Cuanto más grande el valor, más seguros podemos estar de la certeza de la hipótesis nula; y cuanto más pequeño sea, más seguros podemos estar de la hipótesis alternativa.\n",
    "    \n",
    "    Teniendo esto en cuenta, debemos establecer una $α$ acorde a la naturaleza del problema. En algunos contrastes, debemos ser extremadamente estrictos para afirmar la hipótesis alternativa como verdadera, por lo que debemos establecer una $α$ muy, muy baja como $0.01$ o incluso $0.001$. En la mayoría de los casos, este umbral se suele establecer en $0.05$, representando que estamos dispuestos a tomar un riesgo de, como mucho, un 5% de aceptar como verdadera la hipótesis alternativa cuando en realidad la verdadera es la nula.\n",
    "    \n",
    "    Este error se conoce como error de tipo I. Existe también el error de tipo II, que se comete al aceptar la hipótesis nula como verdadera, cuando realmente la verdadera es la alternativa.\n",
    "\n",
    "| | Contraste $H_0$ | Contraste $H_1$ |\n",
    "|-|--|--|\n",
    "| __Real $H_0$__ | OK | Tipo I |\n",
    "| __Real $H_1$__ | Tipo II | OK |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dc345",
   "metadata": {},
   "source": [
    "- Ejemplo\n",
    "    - $α = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # nivel de significancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b696c",
   "metadata": {},
   "source": [
    "3. En función de la hipótesis que queramos contrastar y de la distribución de los datos, debemos seleccionar una prueba u otra. Algunas pruebas nos permiten comparar estadísticos como promedios y medianas, otras son útiles para comparar frecuencias de valores. Las pruebas además se categorizan en paramétricas y no paramétricas.\n",
    "<br>\n",
    "\n",
    "    - Las pruebas paramétricas asumen que la distribución de los datos sigue un modelo específico. La mayoría asumen que la distribución es normal y que existe homogeneidad de varianzas. Antes de aplicar una prueba paramétrica, debemos comprobar que estos requisitos se cumplen para nuestros datos mediante pruebas específicas. Dados los pre-requisitos, no siempre vamos a poder aplicar una prueba paramétrica. No obstante, cuando podamos deben ser nuestra primera opción, ya que son mas potentes.\n",
    "    \n",
    "    <br>\n",
    "      \n",
    "    - Cuando no es posible aplicar una prueba paramétrica porque nuestros datos no cumplen alguno de los requisitos, debemos recurrir a pruebas no paramétricas. Lo bueno de estas pruebas es que no necesitamos asumir nada acerca de nuestros datos y podemos aplicarlas siempre que queramos, pero son una opción menos eficaz que su contraparte paramétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3894c",
   "metadata": {},
   "source": [
    "| Comparación      | Prueba paramétrica       | Asunciones                                      | Contraparte no paramétrica       |\n",
    "|------------------| ------------------------ | ----------------------------------------------- | -------------------------------- |\n",
    "| Posición central | _**t de Student**_       | Normalidad de datos y homogeneidad de varianzas | _**Mann-Whitney U**_             |\n",
    "| Dispersión       | _**Prueba F (ANOVA)**_   | Normalidad de datos y homogeneidad de varianzas | _**Kruskal-Wallis**_             |\n",
    "| Frecuencia       | _**Chi-cuadrado**_       | Mínimo de 5 casos para cada categoría           | _**Prueba de Fisher exacto**_    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b34872",
   "metadata": {},
   "source": [
    "- Para comparar la similitud de los dos conjuntos de datos, podemos comparar sus medias mediante la prueba **t de Student** para dos muestras independientes. En caso de no cumplirse las asunciones para esta prueba paramétrica, podemos utilizar la prueba **U de Mann-Whitney** y comparar con ella las medianas, en lugar de las medias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3833e",
   "metadata": {},
   "source": [
    "#### Comprobamos si las muestras son normales\n",
    "\n",
    "Para comprobar si una muestra es normal usaremos la función _**stats.normaltest()**_.\n",
    "- Se basa en la prueba de _D'Agostino_ y _Pearson_ que combina **asimetría** (_skewness_) y **curtosis** (_kurtosis_) para producir una prueba global de normalidad.\n",
    "\n",
    "\n",
    "Esta función retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "\n",
    "- El valor de _**statistic**_ representa la diferencia entre la distribución y una distribución normal.\n",
    "    - Mientras más grande sea el valor de _**statistic**_ más diferente será esa distribución de una distribución normal.\n",
    "---\n",
    "\n",
    "- El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o más extremo que el observado si los datos son realmente normales.\n",
    "    - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "    - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que los datos sigan una distribución normal.\n",
    "    - Si _**pvalue**_ > _**alpha**_, decimos que es probable que los datos sigan una distribución normal.\n",
    "    \n",
    "    \n",
    "De forma resumida:\n",
    "- _**statistic**_ nos dice qué tan diferente es la distribución de la muestra de una normal.\n",
    "- _**pvalue**_ nos dice qué tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4324120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "student = True # Asumimos que usaremos la t de Student\n",
    "\n",
    "# Aplicaremos stats.normaltest() a ambas muestras y compararemos con alpha, con esto vamos a verificar si son distribuciones normales o no.\n",
    "\n",
    "_, p_muestra_1 = stats.normaltest(muestra_1)\n",
    "_, p_muestra_2 = stats.normaltest(muestra_2)\n",
    "\n",
    "if p_muestra_1 < alpha:\n",
    "    print(f\"muestra_1 no se ajusta a una distribución normal (p = {p_muestra_1})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"muestra_1 tiene una distribución normal (p = {p_muestra_1})\")\n",
    "    \n",
    "if p_muestra_2 < alpha:\n",
    "    print(f\"muestra_2 no se ajusta a una distribución normal (p = {p_muestra_2})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"muestra_2 tiene una distribución normal (p = {p_muestra_2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20d91f",
   "metadata": {},
   "source": [
    "#### Comprobamos la homogeneidad de varianzas\n",
    "\n",
    "Para comprobar la homogeneidad de varianzas entre 2 muestras usaremos la función _**stats.levene()**_.\n",
    "\n",
    "Esta función retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "\n",
    "- El valor de _**statistic**_ representa la diferencia entre las varianzas de ambos grupos.\n",
    "    - Mientras más grande sea el valor de _**statistic**_ más diferente serán esas varianzas.\n",
    "---\n",
    "\n",
    "- El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o más extremo que el observado si las varianzas de los grupos son iguales.\n",
    "    - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "    - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las varianzas de los grupos sean iguales.\n",
    "    - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las varianzas de los grupos sean iguales.\n",
    "\n",
    "De forma resumida:\n",
    "- _**statistic**_ nos dice qué tan diferentes son las varianzas de ambas muestras.\n",
    "- _**pvalue**_ nos dice qué tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb958f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_levene = stats.levene(muestra_1, muestra_2)\n",
    "\n",
    "if p_levene < alpha:\n",
    "    print(f\"Las varianzas no son homogeneas (p = {p_levene})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"Las varianzas son homogeneas (p = {p_levene})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada47903",
   "metadata": {},
   "source": [
    "#### Calculamos la _t de Student_ o la _U de Mann-Whitney_, dependiendo de si se cumplen las asunciones\n",
    "\n",
    "- _**t de Student**_ (Prueba Paramétrica, se cumplen las 2 asunciones anteriores):\n",
    "    - Función _**stats.ttest_ind()**_.\n",
    "    - Esta función retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "    \n",
    "        - El valor de _**statistic**_ (también llamado _**t**_ en este caso) representa la diferencia entre las medias de ambos grupos.\n",
    "            - Mientras más grande sea el valor de _**statistic**_ más diferente serán esas medias.\n",
    "            \n",
    "            ---\n",
    "\n",
    "        - El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o más extremo que el observado si las medias de los grupos son iguales.\n",
    "            - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "            - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las medias de los grupos sean iguales.\n",
    "            - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las medias de los grupos sean iguales.\n",
    "\n",
    "    De forma resumida:\n",
    "    - _**statistic**_ nos dice qué tan diferentes son las medias de ambas muestras.\n",
    "    - _**pvalue**_ nos dice qué tan probable es que esa diferencia se deba al azar.\n",
    "---\n",
    "- _**U de Mann-Whitney**_ (Prueba No Paramétrica, no se cumple al menos 1 de las asunciones anteriores):\n",
    "\n",
    "    - Función _**stats.mannwhitneyu()**_.\n",
    "    - Esta función retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "    \n",
    "        - El valor de _**statistic**_ (también llamado _**U**_ en este caso) representa la diferencia entre las distribuciones de ambos grupos.\n",
    "            - Mientras más grande sea el valor de _**statistic**_ más diferente serán ambas distribuciones.\n",
    "            ---\n",
    "\n",
    "        - El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o más extremo que el observado si las distribuciones de los grupos son iguales..\n",
    "            - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "            - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las distribuciones de los grupos sean iguales.\n",
    "            - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las distribuciones de los grupos sean iguales.\n",
    "\n",
    "    De forma resumida:\n",
    "    - _**statistic**_ nos dice qué tan diferentes son las distribuciones de ambas muestras.\n",
    "    - _**pvalue**_ nos dice qué tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097338ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos stats.ttest_ind() o stats.mannwhitneyu() dependiendo del caso\n",
    "\n",
    "if student:\n",
    "    \n",
    "    t, p = stats.ttest_ind(muestra_1, muestra_2)\n",
    "    \n",
    "    print(f\"El valor t de Student es: {t}\")\n",
    "    print(f\"El valor p es: {p}\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    u, p = stats.mannwhitneyu(muestra_1, muestra_2)\n",
    "    \n",
    "    print(f\"El valor U de Mann-Whitney es: {u}\")\n",
    "    print(f\"El valor p es: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9011b",
   "metadata": {},
   "source": [
    "4. Cuando realicemos una de estas pruebas, vamos a obtener un valor $p$. Si ese valor es menor a nuestra $α$, interpretamos la prueba rechazando la $H_0$. Por el contrario, si es mayor o igual a nuestra $α$, tomamos $H_0$ como cierta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El valor de significancia p es {p:2e}\")\n",
    "\n",
    "print(\"La significancia es\", \"menor\" if alpha > p else \"mayor\", f\"a {alpha}\")\n",
    "\n",
    "print(\"Interpretación: la hipótesis nula (H0) es\", \"falsa.\" if alpha > p else \"cierta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb413fb-f8f6-44e2-81b7-0b5125dd7f43",
   "metadata": {},
   "source": [
    "### Resumen de Funciones\n",
    "\n",
    "|Función                   |Descripción                                                                      |\n",
    "|--------------------------|---------------------------------------------------------------------------------|\n",
    "|_**stats.normaltest()**_  |Prueba de **normalidad** sobre una muestra de datos.                             |\n",
    "|_**stats.levene()**_      |Prueba de **homogeneidad de varianzas** entre dos muestras de datos.             |\n",
    "|_**stats.ttest_ind()**_   |Prueba de **comparación de medias** de dos grupos independientes.                |\n",
    "|_**stats.mannwhitneyu()**_|Prueba de **comparación** de dos grupos independientes **sin asumir normalidad**.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848e2c3-e23c-4b24-94bf-9c0d25a391f0",
   "metadata": {},
   "source": [
    "**Es importante aclarar que estas pruebas no siempre son concluyentes. Hay que considerar otros factores que afectan los resultados, como el tamaño de las muestras, outliers y las formas de las distribuciones.**\n",
    "\n",
    "**Es recomendable acompañar todo esto con visualizaciones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad49a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
