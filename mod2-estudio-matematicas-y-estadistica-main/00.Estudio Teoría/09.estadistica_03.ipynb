{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7941abf",
   "metadata": {},
   "source": [
    "## Estad√≠stica Inferencial\n",
    "\n",
    "Se llama estad√≠stica inferencial a la rama de la Estad√≠stica encargada de hacer deducciones, es decir, inferir propiedades, conclusiones y tendencias, a partir de una muestra del conjunto. Su papel es interpretar, hacer proyecciones y comparaciones.\n",
    "\n",
    "- Correlaciones Lineales\n",
    "- Outliers\n",
    "    - Puntuaci√≥n Z (Z-Score)\n",
    "    - Valle de Tukey\n",
    "- Contraste de Hipotesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e62b5-455d-4494-b483-bcbe817de050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Versiones\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\")\n",
    "print(f\"seaborn=={sns.__version__}\")\n",
    "print(f\"scipy=={scipy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9727c00-26a4-4389-9096-9b3fbd0112ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "# Estos datos representan: ENGINESIZE, FUELCONSUMPTION_CITY, CYLINDERS, CO2EMISSIONS del csv FuelConsumptionCo2\n",
    "\n",
    "with open(file = \"../Data/ENGINESIZE.pkl\", mode = \"br\") as file:\n",
    "    engine_size = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/FUELCONSUMPTION_CITY.pkl\", mode = \"br\") as file:\n",
    "    fuelconsumption_city = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/CYLINDERS.pkl\", mode = \"br\") as file:\n",
    "    cylinders = pickle.load(file)\n",
    "    \n",
    "with open(file = \"../Data/CO2EMISSIONS.pkl\", mode = \"br\") as file:\n",
    "    co2_emissions = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dccd99",
   "metadata": {},
   "source": [
    "### Correlaci√≥n entre 2 variables\n",
    "\n",
    "La correlaci√≥n entre dos variables es una medida que indica la fuerza y la direcci√≥n de la relaci√≥n lineal entre ellas. Tambi√©n se puede entender como qu√© tan probable es que una variable cambie cuando la otra variable cambia.\n",
    "\n",
    "El m√©todo que se va a utilizar para calcular la correlaci√≥n entre 2 variables es el **coeficiente de correlaci√≥n lineal de Pearson**. El cual mide √∫nicamente la relaci√≥n entre ambas variables sin considerar dependencias y siempre buscando una correlaci√≥n lineal. Se suele denotar con la letra griega _**rho**_ $\\rho$.\n",
    "\n",
    "Para poder calcular la correlaci√≥n utilizamos el c√°lculo de la covarianza entre ambas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a187d79-473e-407b-abd1-4cf9b0eb0b1e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Large Cov(X, Y) = \\frac{\\sum_{i=1}^{n}(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{n}\\\\\n",
    "\\Large \\rho = \\frac{Cov(X, Y)}{\\sigma_{x}\\sigma_{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3be6aa",
   "metadata": {},
   "source": [
    "Donde el valor de $\\rho$ puede tomar valores desde -1 hasta +1 y de acuerdo a su valor se pueden asignar las siguientes categor√≠as:\n",
    "\n",
    "- 0: asociaci√≥n nula.\n",
    "- Âúü 0.1: asociaci√≥n peque√±a.\n",
    "- Âúü 0.3: asociaci√≥n mediana.\n",
    "- Âúü 0.5: asociaci√≥n moderada.\n",
    "- Âúü 0.7: asociaci√≥n alta.\n",
    "- Âúü 0.9: asociaci√≥n muy alta.\n",
    "\n",
    "Este estad√≠stico, como muchos otros, suele venir con un valor $\\rho$ que representa su nivel de significancia. Esto lo veremos m√°s en detalle en el contraste de hip√≥tesis.\n",
    "\n",
    "Para calcular el **coeficiente de correlaci√≥n lineal de Pearson** usaremos la funci√≥n **stats.pearsonr()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59f583-32f3-40fd-a94d-ff5810f0bbda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coeficiente de correlaci√≥n lineal de Pearson\n",
    "# Variables engine_size y fuelconsumption_city\n",
    "\n",
    "stats.pearsonr(engine_size, fuelconsumption_city)\n",
    "\n",
    "# El primer valor es la correlaci√≥n, el segundo su nivel de significacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c1e88-d311-4d20-805c-34bee746bf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para obtener el primer valor\n",
    "\n",
    "stats.pearsonr(engine_size, fuelconsumption_city)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99bfafb-1a19-47f5-9d8a-01480c7c2513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (engine_size)\n",
    "\n",
    "print(f\"Correlaci√≥n engine_size/engine_size: {stats.pearsonr(engine_size, engine_size)[0]}\")\n",
    "print(f\"Correlaci√≥n engine_size/fuelconsumption_city: {stats.pearsonr(engine_size, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlaci√≥n engine_size/cylinders: {stats.pearsonr(engine_size, cylinders)[0]}\")\n",
    "print(f\"Correlaci√≥n engine_size/co2_emissions: {stats.pearsonr(engine_size, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd45fb-6e25-4e15-8449-a1bc686b5cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (fuelconsumption_city)\n",
    "\n",
    "print(f\"Correlaci√≥n fuelconsumption_city/engine_size: {stats.pearsonr(fuelconsumption_city, engine_size)[0]}\")\n",
    "print(f\"Correlaci√≥n fuelconsumption_city/fuelconsumption_city: {stats.pearsonr(fuelconsumption_city, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlaci√≥n fuelconsumption_city/cylinders: {stats.pearsonr(fuelconsumption_city, cylinders)[0]}\")\n",
    "print(f\"Correlaci√≥n fuelconsumption_city/co2_emissions: {stats.pearsonr(fuelconsumption_city, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91253ff9-fd22-4b22-8d75-f92f7f6f788f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (cylinders)\n",
    "\n",
    "print(f\"Correlaci√≥n cylinders/engine_size: {stats.pearsonr(cylinders, engine_size)[0]}\")\n",
    "print(f\"Correlaci√≥n cylinders/fuelconsumption_city: {stats.pearsonr(cylinders, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlaci√≥n cylinders/cylinders: {stats.pearsonr(cylinders, cylinders)[0]}\")\n",
    "print(f\"Correlaci√≥n cylinders/co2_emissions: {stats.pearsonr(cylinders, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d7d4c-f5ba-4664-8d73-864f09af6c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Probamos con las otras variables (co2_emissions)\n",
    "\n",
    "print(f\"Correlaci√≥n co2_emissions/engine_size: {stats.pearsonr(co2_emissions, engine_size)[0]}\")\n",
    "print(f\"Correlaci√≥n co2_emissions/fuelconsumption_city: {stats.pearsonr(co2_emissions, fuelconsumption_city)[0]}\")\n",
    "print(f\"Correlaci√≥n co2_emissions/cylinders: {stats.pearsonr(co2_emissions, cylinders)[0]}\")\n",
    "print(f\"Correlaci√≥n co2_emissions/co2_emissions: {stats.pearsonr(co2_emissions, co2_emissions)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2e2b-1608-4be3-8595-4e63fba328ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podriamos crear una matriz de correlaciones\n",
    "\n",
    "variables = [engine_size, fuelconsumption_city, cylinders, co2_emissions]\n",
    "\n",
    "matriz_corr = list()\n",
    "\n",
    "for variable1 in variables:\n",
    "    \n",
    "    fila = list()\n",
    "    \n",
    "    for variable2 in variables:\n",
    "        \n",
    "        fila.append(stats.pearsonr(variable1, variable2)[0])\n",
    "        \n",
    "    matriz_corr.append(fila)\n",
    "    \n",
    "np.array(matriz_corr)\n",
    "\n",
    "# Variables: engine_size, fuelconsumption_city, cylinders, co2_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648bad4",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Un outlier es un individuo de una poblaci√≥n con **caracter√≠sticas/valores extremadamente at√≠picos**. Existen varios m√©todos para detectar outliers, pero los m√°s comunes aprovechan las medidas de dispersi√≥n para conseguirlo.\n",
    "\n",
    "Un mismo individuo puede ser considerado como outlier por un m√©todo, y como normal por otro, por lo que debemos tener en cuenta c√≥mo funcionan antes de aplicarlos.\n",
    "\n",
    "A continuaci√≥n veremos c√≥mo podemos usar las medidas de **rango intercuartil** (_ric_ o _iqr_) y **desviaci√≥n est√°ndar** (_std_) para detectar outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a018d",
   "metadata": {},
   "source": [
    "#### 1. Puntuaci√≥n Z (_Z-Score_)\n",
    "La **puntuaci√≥n z** es una medida que nos dice a qu√© distancia se encuentra un valor de la media en t√©rminos de desviaci√≥n est√°ndar. Si un valor tiene una **puntuaci√≥n z** de -1, quiere decir se encuentra a una desviaci√≥n est√°ndar a la izquierda de la media. En otras palabras, ese valor es igual a la media menos la desviaci√≥n est√°ndar.\n",
    "\n",
    "Resulta que para distribuciones normales, los valores comprendidos entre **puntuaciones z** de -3 y 3 constituyen el 99,7% de todos los datos. Podemos aprovechar esto para declarar cualquier valor con una **puntuaci√≥n z** fuera de ese rango como at√≠pico.\n",
    "\n",
    "Esta forma de detectar outliers es la m√°s sencilla de todas, pero pierde eficacia cuando se trata de distribuciones asim√©tricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una lista de n√∫meros aleatorios con la librer√≠a random\n",
    "array = np.array([random.gauss(100, 15) for _ in range(10_000)])\n",
    "\n",
    "def outliers_z_score(array, z = 3):\n",
    "    \n",
    "    # Calculamos media y std\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    \n",
    "    # Calculamos los limites laterales (ùúá ¬± z*ùúé)\n",
    "    lim_l = mean - z*std\n",
    "    lim_r = mean + z*std\n",
    "    \n",
    "    # Filtramos los elementos del array, los que esten fuera de los limites laterales.\n",
    "    outliers = [elem for elem in array if elem < lim_l or elem > lim_r]\n",
    "    \n",
    "    # Filtramos los elementos del array, los que no pertenezcan a outliers.\n",
    "    normal_data = [elem for elem in array if elem not in outliers]\n",
    "    \n",
    "    # Retornamos ambos arrays, uno con los datos sin outliers, otro con los outliers\n",
    "    return np.array(normal_data), np.array(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data, outliers = outliers_z_score(array)\n",
    "\n",
    "print(f\"Total de no-outliers: {len(normal_data)}\")\n",
    "print(f\"Total de outliers: {len(outliers)}\")\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(array)\n",
    "std = np.std(array)\n",
    "\n",
    "# Limites laterales\n",
    "lim_l = mean - 3*std\n",
    "lim_r = mean + 3*std\n",
    "\n",
    "# No-Outliers\n",
    "plt.hist(normal_data, bins = 50, color = \"blue\")\n",
    "\n",
    "# Outliers\n",
    "plt.hist(outliers, bins = 50, color = \"red\")\n",
    "\n",
    "# ùúá ¬± 3ùúé\n",
    "plt.axvline(lim_l, color = \"black\", linestyle = \"--\")\n",
    "plt.axvline(lim_r, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428624aa",
   "metadata": {},
   "source": [
    "#### 2. La valla de Tukey (_Tukey's Fence Rule_)\n",
    "Este m√©todo es algo m√°s robusto ante distribuciones asim√©tricas que el anterior.\n",
    "\n",
    "Igual que con las **puntuaciones z**, necesitamos establecer unos l√≠mites a la izquierda y a la derecha de la distribuci√≥n. Esta vez, vamos a aprovechar los cuantiles. Tomando como referencia los cuartiles **Q1** y **Q3**, nos alejamos $1.5*ric$ de cada uno de ellos a la izquierda y a la derecha, respectivamente. Esos ser√°n nuestros puntos de corte. Cualquier valor que se encuentre fuera de ese rango, lo consideramos como at√≠pico.\n",
    "\n",
    "Podemos modificar el multiplicador del rango intercuartil ($k=1.5$) a nuestro antojo, seg√∫n necesitemos ser m√°s o menos estrictos. Al incrementar el multiplicador, incrementamos el rango de normalidad, por lo que tendremos menos outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04154070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_tukey(array, k = 1.5):\n",
    "    \n",
    "    # Calculamos los cuartiles Q1 y Q3\n",
    "    q1 = np.quantile(array, 0.25)\n",
    "    q3 = np.quantile(array, 0.75)\n",
    "    \n",
    "    # Rango InterCuartil\n",
    "    ric = q3 - q1\n",
    "    \n",
    "    # Calculamos los l√≠mites laterales\n",
    "    lim_l = q1 - k*ric\n",
    "    lim_r = q3 + k*ric\n",
    "    \n",
    "    # Filtramos los elementos del array, los que esten fuera de los limites laterales.\n",
    "    outliers = [elem for elem in array if elem < lim_l or elem > lim_r]\n",
    "    \n",
    "    \n",
    "    # Filtramos los elementos del array, los que no pertenezcan a outliers.\n",
    "    normal_data = [elem for elem in array if elem not in outliers]\n",
    "    \n",
    "    # Retornamos ambos arrays, uno con los datos sin outliers, otro con los outliers\n",
    "    return np.array(normal_data), np.array(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data, outliers = outliers_tukey(array)\n",
    "\n",
    "print(f\"Total de no-outliers: {len(normal_data)}\")\n",
    "print(f\"Total de outliers: {len(outliers)}\")\n",
    "\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d28e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.quantile(array, 0.25)\n",
    "q3 = np.quantile(array, 0.75)\n",
    "ric = q3 - q1\n",
    "\n",
    "lim_l = q1 - 1.5*ric\n",
    "lim_r = q3 + 1.5*ric\n",
    "\n",
    "# No-Outliers\n",
    "plt.hist(normal_data, bins = 50, color = \"blue\")\n",
    "\n",
    "# Outliers\n",
    "plt.hist(outliers, bins = 50, color = \"red\")\n",
    "\n",
    "# Q1 - 1.5*ric\n",
    "plt.axvline(lim_l, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "# Q3 + 1.5*ric\n",
    "plt.axvline(lim_r, color = \"black\", linestyle = \"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56078086",
   "metadata": {},
   "source": [
    "Existen muchos otros m√©todos que aprovechan estad√≠sticos como el **MAD (Median Absolute Deviation)**, o algoritmos de clustering como **DBSCAN** para detectar outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a109e4",
   "metadata": {},
   "source": [
    "### Contraste de hip√≥tesis\n",
    "\n",
    "El contraste de hip√≥tesis es una t√©cnica de la estad√≠stica inferencial que nos permite tomar decisiones sobre afirmaciones o suposiciones acerca de una poblaci√≥n, basadas en la informaci√≥n obtenida de una muestra de esa poblaci√≥n.\n",
    "\n",
    "1. Para llevar a cabo un contraste de hip√≥tesis necesitamos primero formular dos hip√≥tesis. La primera se conoce como hip√≥tesis nula ($H_0$), y es una suposici√≥n o afirmaci√≥n de que la condici√≥n que queremos probar o refutar no es cierta. Por ejemplo, si queremos comprobar si el cociente intelectual promedio de los alumnos de cuarto de la ESO es diferente al cociente intelectual promedio de la poblaci√≥n general, la hip√≥tesis nula ser√≠a que son iguales, que no existe diferencia.\n",
    "\n",
    "    Por el contrario, tenemos tambi√©n la hip√≥tesis alternativa ($H_1$), que no es m√°s que lo opuesto a la nula. En ese caso, la $H_1$ ser√≠a que el alumno promedio de cuarto de la ESO tiene un CI diferente (mayor o menor) que el el ciudadano promedio de Espa√±a.\n",
    "\n",
    "    El contraste de hip√≥tesis nos permite tomar una decision al respecto de estas dos hip√≥tesis. Nos da cierta certeza para tomar una u otra como la verdadera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a3ea3",
   "metadata": {},
   "source": [
    "- Ejemplo\n",
    "    - $H_0$: las emisiones de CO2 de _**FORD**_ son en promedio **iguales** que las emisiones de CO2 de _**MERCEDES-BENZ**_.\n",
    "    - $H_1$: las emisiones de CO2 de _**FORD**_ son en promedio **diferentes** que las emisiones de CO2 de _**MERCEDES-BENZ**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb18d20-6465-42b3-8fea-71368a45c2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vamos a extraer muestras del csv FuelConsumptionCo2\n",
    "# Cada array representa una marca de coche y vamos a extraer las emisiones de CO2\n",
    "# Trabajaremos con 3 muestras, el primer ejemplo ser√°n con las muestras 1 y 2\n",
    "# Se pueden hacer otros ejemplos con las muestras 1 y 3 o 2 y 3.\n",
    "\n",
    "# MAKE == \"FORD\"\n",
    "with open(file = \"../Data/muestra_1.pkl\", mode = \"br\") as file:\n",
    "    muestra_1 = pickle.load(file)\n",
    "\n",
    "# MAKE == \"MERCEDES-BENZ\"\n",
    "with open(file = \"../Data/muestra_2.pkl\", mode = \"br\") as file:\n",
    "    muestra_2 = pickle.load(file)\n",
    "\n",
    "# MAKE == \"CHEVROLET\"\n",
    "with open(file = \"../Data/muestra_3.pkl\", mode = \"br\") as file:\n",
    "    muestra_3 = pickle.load(file)\n",
    "\n",
    "print(f\"Datos FORD: {len(muestra_1)}\")\n",
    "print(f\"Datos MERCEDES-BENZ: {len(muestra_2)}\")\n",
    "print(f\"Datos CHEVROLET: {len(muestra_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180abc-f080-4e37-b615-d0431d3f187d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Veamos las distribuciones de los datos en una gr√°fica\n",
    "\n",
    "sns.kdeplot(muestra_1, color = \"magenta\", label = \"FORD\")\n",
    "sns.kdeplot(muestra_2, color = \"red\", label = \"MERCEDES-BENZ\")\n",
    "sns.kdeplot(muestra_3, color = \"blue\", label = \"CHEVROLET\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452e1bf",
   "metadata": {},
   "source": [
    "2. Esto lo conseguimos estableciendo un nivel de significancia. Es, en esencia, el nivel de confianza de los resultados del contraste. Se representa con la letra griega **alpha** $Œ±$ y nos indica el valor m√°ximo que aceptamos que tenga el valor $p$.\n",
    "    \n",
    "    Ahora, el valor $p$ representa una probabilidad. Concretamente es la probabilidad que tenemos de obtener una muestra como la que usamos en el contraste, dado que la hip√≥tesis nula sea verdadera. En otras palabras, es un valor de confianza. Cuanto m√°s grande el valor, m√°s seguros podemos estar de la certeza de la hip√≥tesis nula; y cuanto m√°s peque√±o sea, m√°s seguros podemos estar de la hip√≥tesis alternativa.\n",
    "    \n",
    "    Teniendo esto en cuenta, debemos establecer una $Œ±$ acorde a la naturaleza del problema. En algunos contrastes, debemos ser extremadamente estrictos para afirmar la hip√≥tesis alternativa como verdadera, por lo que debemos establecer una $Œ±$ muy, muy baja como $0.01$ o incluso $0.001$. En la mayor√≠a de los casos, este umbral se suele establecer en $0.05$, representando que estamos dispuestos a tomar un riesgo de, como mucho, un 5% de aceptar como verdadera la hip√≥tesis alternativa cuando en realidad la verdadera es la nula.\n",
    "    \n",
    "    Este error se conoce como error de tipo I. Existe tambi√©n el error de tipo II, que se comete al aceptar la hip√≥tesis nula como verdadera, cuando realmente la verdadera es la alternativa.\n",
    "\n",
    "| | Contraste $H_0$ | Contraste $H_1$ |\n",
    "|-|--|--|\n",
    "| __Real $H_0$__ | OK | Tipo I |\n",
    "| __Real $H_1$__ | Tipo II | OK |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dc345",
   "metadata": {},
   "source": [
    "- Ejemplo\n",
    "    - $Œ± = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # nivel de significancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b696c",
   "metadata": {},
   "source": [
    "3. En funci√≥n de la hip√≥tesis que queramos contrastar y de la distribuci√≥n de los datos, debemos seleccionar una prueba u otra. Algunas pruebas nos permiten comparar estad√≠sticos como promedios y medianas, otras son √∫tiles para comparar frecuencias de valores. Las pruebas adem√°s se categorizan en param√©tricas y no param√©tricas.\n",
    "<br>\n",
    "\n",
    "    - Las pruebas param√©tricas asumen que la distribuci√≥n de los datos sigue un modelo espec√≠fico. La mayor√≠a asumen que la distribuci√≥n es normal y que existe homogeneidad de varianzas. Antes de aplicar una prueba param√©trica, debemos comprobar que estos requisitos se cumplen para nuestros datos mediante pruebas espec√≠ficas. Dados los pre-requisitos, no siempre vamos a poder aplicar una prueba param√©trica. No obstante, cuando podamos deben ser nuestra primera opci√≥n, ya que son mas potentes.\n",
    "    \n",
    "    <br>\n",
    "      \n",
    "    - Cuando no es posible aplicar una prueba param√©trica porque nuestros datos no cumplen alguno de los requisitos, debemos recurrir a pruebas no param√©tricas. Lo bueno de estas pruebas es que no necesitamos asumir nada acerca de nuestros datos y podemos aplicarlas siempre que queramos, pero son una opci√≥n menos eficaz que su contraparte param√©trica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3894c",
   "metadata": {},
   "source": [
    "| Comparaci√≥n      | Prueba param√©trica       | Asunciones                                      | Contraparte no param√©trica       |\n",
    "|------------------| ------------------------ | ----------------------------------------------- | -------------------------------- |\n",
    "| Posici√≥n central | _**t de Student**_       | Normalidad de datos y homogeneidad de varianzas | _**Mann-Whitney U**_             |\n",
    "| Dispersi√≥n       | _**Prueba F (ANOVA)**_   | Normalidad de datos y homogeneidad de varianzas | _**Kruskal-Wallis**_             |\n",
    "| Frecuencia       | _**Chi-cuadrado**_       | M√≠nimo de 5 casos para cada categor√≠a           | _**Prueba de Fisher exacto**_    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b34872",
   "metadata": {},
   "source": [
    "- Para comparar la similitud de los dos conjuntos de datos, podemos comparar sus medias mediante la prueba **t de Student** para dos muestras independientes. En caso de no cumplirse las asunciones para esta prueba param√©trica, podemos utilizar la prueba **U de Mann-Whitney** y comparar con ella las medianas, en lugar de las medias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3833e",
   "metadata": {},
   "source": [
    "#### Comprobamos si las muestras son normales\n",
    "\n",
    "Para comprobar si una muestra es normal usaremos la funci√≥n _**stats.normaltest()**_.\n",
    "- Se basa en la prueba de _D'Agostino_ y _Pearson_ que combina **asimetr√≠a** (_skewness_) y **curtosis** (_kurtosis_) para producir una prueba global de normalidad.\n",
    "\n",
    "\n",
    "Esta funci√≥n retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "\n",
    "- El valor de _**statistic**_ representa la diferencia entre la distribuci√≥n y una distribuci√≥n normal.\n",
    "    - Mientras m√°s grande sea el valor de _**statistic**_ m√°s diferente ser√° esa distribuci√≥n de una distribuci√≥n normal.\n",
    "---\n",
    "\n",
    "- El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado si los datos son realmente normales.\n",
    "    - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "    - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que los datos sigan una distribuci√≥n normal.\n",
    "    - Si _**pvalue**_ > _**alpha**_, decimos que es probable que los datos sigan una distribuci√≥n normal.\n",
    "    \n",
    "    \n",
    "De forma resumida:\n",
    "- _**statistic**_ nos dice qu√© tan diferente es la distribuci√≥n de la muestra de una normal.\n",
    "- _**pvalue**_ nos dice qu√© tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4324120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "student = True # Asumimos que usaremos la t de Student\n",
    "\n",
    "# Aplicaremos stats.normaltest() a ambas muestras y compararemos con alpha, con esto vamos a verificar si son distribuciones normales o no.\n",
    "\n",
    "_, p_muestra_1 = stats.normaltest(muestra_1)\n",
    "_, p_muestra_2 = stats.normaltest(muestra_2)\n",
    "\n",
    "if p_muestra_1 < alpha:\n",
    "    print(f\"muestra_1 no se ajusta a una distribuci√≥n normal (p = {p_muestra_1})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"muestra_1 tiene una distribuci√≥n normal (p = {p_muestra_1})\")\n",
    "    \n",
    "if p_muestra_2 < alpha:\n",
    "    print(f\"muestra_2 no se ajusta a una distribuci√≥n normal (p = {p_muestra_2})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"muestra_2 tiene una distribuci√≥n normal (p = {p_muestra_2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20d91f",
   "metadata": {},
   "source": [
    "#### Comprobamos la homogeneidad de varianzas\n",
    "\n",
    "Para comprobar la homogeneidad de varianzas entre 2 muestras usaremos la funci√≥n _**stats.levene()**_.\n",
    "\n",
    "Esta funci√≥n retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "\n",
    "- El valor de _**statistic**_ representa la diferencia entre las varianzas de ambos grupos.\n",
    "    - Mientras m√°s grande sea el valor de _**statistic**_ m√°s diferente ser√°n esas varianzas.\n",
    "---\n",
    "\n",
    "- El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado si las varianzas de los grupos son iguales.\n",
    "    - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "    - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las varianzas de los grupos sean iguales.\n",
    "    - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las varianzas de los grupos sean iguales.\n",
    "\n",
    "De forma resumida:\n",
    "- _**statistic**_ nos dice qu√© tan diferentes son las varianzas de ambas muestras.\n",
    "- _**pvalue**_ nos dice qu√© tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb958f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_levene = stats.levene(muestra_1, muestra_2)\n",
    "\n",
    "if p_levene < alpha:\n",
    "    print(f\"Las varianzas no son homogeneas (p = {p_levene})\")\n",
    "    student = False\n",
    "else:\n",
    "    print(f\"Las varianzas son homogeneas (p = {p_levene})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada47903",
   "metadata": {},
   "source": [
    "#### Calculamos la _t de Student_ o la _U de Mann-Whitney_, dependiendo de si se cumplen las asunciones\n",
    "\n",
    "- _**t de Student**_ (Prueba Param√©trica, se cumplen las 2 asunciones anteriores):\n",
    "    - Funci√≥n _**stats.ttest_ind()**_.\n",
    "    - Esta funci√≥n retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "    \n",
    "        - El valor de _**statistic**_ (tambi√©n llamado _**t**_ en este caso) representa la diferencia entre las medias de ambos grupos.\n",
    "            - Mientras m√°s grande sea el valor de _**statistic**_ m√°s diferente ser√°n esas medias.\n",
    "            \n",
    "            ---\n",
    "\n",
    "        - El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado si las medias de los grupos son iguales.\n",
    "            - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "            - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las medias de los grupos sean iguales.\n",
    "            - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las medias de los grupos sean iguales.\n",
    "\n",
    "    De forma resumida:\n",
    "    - _**statistic**_ nos dice qu√© tan diferentes son las medias de ambas muestras.\n",
    "    - _**pvalue**_ nos dice qu√© tan probable es que esa diferencia se deba al azar.\n",
    "---\n",
    "- _**U de Mann-Whitney**_ (Prueba No Param√©trica, no se cumple al menos 1 de las asunciones anteriores):\n",
    "\n",
    "    - Funci√≥n _**stats.mannwhitneyu()**_.\n",
    "    - Esta funci√≥n retorna dos valores: _**statistic**_ y _**pvalue**_.\n",
    "    \n",
    "        - El valor de _**statistic**_ (tambi√©n llamado _**U**_ en este caso) representa la diferencia entre las distribuciones de ambos grupos.\n",
    "            - Mientras m√°s grande sea el valor de _**statistic**_ m√°s diferente ser√°n ambas distribuciones.\n",
    "            ---\n",
    "\n",
    "        - El valor de _**pvalue**_ es la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado si las distribuciones de los grupos son iguales..\n",
    "            - Para entender el valor de _**pvalue**_ debemos compararlo con _**alpha**_ (el nivel de significancia):\n",
    "            - Si _**pvalue**_ < _**alpha**_, decimos que es poco probable que las distribuciones de los grupos sean iguales.\n",
    "            - Si _**pvalue**_ > _**alpha**_, decimos que es probable que las distribuciones de los grupos sean iguales.\n",
    "\n",
    "    De forma resumida:\n",
    "    - _**statistic**_ nos dice qu√© tan diferentes son las distribuciones de ambas muestras.\n",
    "    - _**pvalue**_ nos dice qu√© tan probable es que esa diferencia se deba al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097338ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos stats.ttest_ind() o stats.mannwhitneyu() dependiendo del caso\n",
    "\n",
    "if student:\n",
    "    \n",
    "    t, p = stats.ttest_ind(muestra_1, muestra_2)\n",
    "    \n",
    "    print(f\"El valor t de Student es: {t}\")\n",
    "    print(f\"El valor p es: {p}\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    u, p = stats.mannwhitneyu(muestra_1, muestra_2)\n",
    "    \n",
    "    print(f\"El valor U de Mann-Whitney es: {u}\")\n",
    "    print(f\"El valor p es: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9011b",
   "metadata": {},
   "source": [
    "4. Cuando realicemos una de estas pruebas, vamos a obtener un valor $p$. Si ese valor es menor a nuestra $Œ±$, interpretamos la prueba rechazando la $H_0$. Por el contrario, si es mayor o igual a nuestra $Œ±$, tomamos $H_0$ como cierta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El valor de significancia p es {p:2e}\")\n",
    "\n",
    "print(\"La significancia es\", \"menor\" if alpha > p else \"mayor\", f\"a {alpha}\")\n",
    "\n",
    "print(\"Interpretaci√≥n: la hip√≥tesis nula (H0) es\", \"falsa.\" if alpha > p else \"cierta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb413fb-f8f6-44e2-81b7-0b5125dd7f43",
   "metadata": {},
   "source": [
    "### Resumen de Funciones\n",
    "\n",
    "|Funci√≥n                   |Descripci√≥n                                                                      |\n",
    "|--------------------------|---------------------------------------------------------------------------------|\n",
    "|_**stats.normaltest()**_  |Prueba de **normalidad** sobre una muestra de datos.                             |\n",
    "|_**stats.levene()**_      |Prueba de **homogeneidad de varianzas** entre dos muestras de datos.             |\n",
    "|_**stats.ttest_ind()**_   |Prueba de **comparaci√≥n de medias** de dos grupos independientes.                |\n",
    "|_**stats.mannwhitneyu()**_|Prueba de **comparaci√≥n** de dos grupos independientes **sin asumir normalidad**.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848e2c3-e23c-4b24-94bf-9c0d25a391f0",
   "metadata": {},
   "source": [
    "**Es importante aclarar que estas pruebas no siempre son concluyentes. Hay que considerar otros factores que afectan los resultados, como el tama√±o de las muestras, outliers y las formas de las distribuciones.**\n",
    "\n",
    "**Es recomendable acompa√±ar todo esto con visualizaciones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad49a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
