{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09695d7",
   "metadata": {},
   "source": [
    "## pandas - Avanzado\n",
    "\n",
    "- Filtros en DataFrames.\n",
    "- Cambiar tipos de datos.\n",
    "- Concatenación de DataFrames.\n",
    "- Merge (join).\n",
    "- Métodos _**.map()**_, _**.applymap()**_ y _**.apply()**_.\n",
    "- Manipulación de NaN's en _**pandas**_.\n",
    "- _**GroupBy**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29793c2-4bee-4d48-a73a-342fc9bff826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Versiones\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"pandas=={pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3d0b6-8bad-4beb-a487-ba869ce9dd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usaremos 2 DataFrames\n",
    "\n",
    "df1 = pd.read_csv(\"../Data/titanic_1.csv\")\n",
    "df2 = pd.read_csv(\"../Data/titanic_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85906c70-bd38-4435-b96f-72d3fe1951f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c26ee7-d089-40a8-b146-5c7f89e05ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930bef63-3286-4872-8e8c-0b77245ceb1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtros en DataFrames\n",
    "\n",
    "Para aplicar filtros o \"máscaras\" en los _**pd.DataFrames()**_ utilizaremos una sintaxis muy similar a _**np.where()**_.\n",
    "\n",
    "La sintaxis se basa en condicionales y para unir 2 o más condiciones usaremos _**&**_, _**|**_ y _**~**_, en lugar de _**and**_, _**or**_ y _**not**_ respectivamente.\n",
    "\n",
    "Si tenemos más de una condición, cada condición se debe agrupar usando paréntesis.\n",
    "\n",
    "| Operador     | Operación     |\n",
    "|--------------|---------------|\n",
    "| **==**       | Igual         |\n",
    "| **!=**       | Diferente     |\n",
    "| **>**        | Mayor que     |\n",
    "| **<**        | Menor que     |\n",
    "| **>=**       | Mayor o igual |\n",
    "| **<=**       | Menor o igual |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746d79a-180c-4615-a46e-296c927f269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para aplicar un filtro usamos los operadores de comparación\n",
    "\n",
    "# Usamos df1\n",
    "\n",
    "df1[\"Age\"] > 18\n",
    "\n",
    "# Esto retorna una pd.Series() con True y False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306608dd-531e-4664-848b-96bc67a4681d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si quisieramos aplicar ese \"filtro\" al DataFrame hariamos un \"indexing\" con el operador\n",
    "\n",
    "df1[df1[\"Age\"] > 18]\n",
    "\n",
    "# Esto nos retorna el DataFrame solo con las filas que cumplen la condición\n",
    "# En este ejemplo filtramos el DataFrame para quedarnos con las filas donde \"Age\" es mayor estricto a 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649fd085-735d-4b2d-91fa-e55c991c4ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podemos unir 2 o más condiciones usando | o &\n",
    "# Cada condición debe de estar entre paréntesis\n",
    "\n",
    "# En este ejemplo usamos |\n",
    "\n",
    "df1[(df1[\"Age\"] > 18) | (df1[\"Sex\"] == \"female\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17138675-0fc9-4bff-bfcd-8ad59d8308ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejemplo usando &\n",
    "\n",
    "df1[(df1[\"Age\"] > 18) & (df1[\"Sex\"] == \"female\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3483e8b-e324-46cd-bcd3-2f04b085d24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf14a7e-0dd4-4108-87a9-e19bf86919be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usamos df2\n",
    "\n",
    "df2[(df2[\"Pclass\"] == 1) | (df2[\"Pclass\"] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370f0b4-13d8-40d0-ac79-dc64461ebff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Es posible hacer un filtro que no tenga ningun resultado\n",
    "# Esto nos retorna un DataFrame vacío\n",
    "\n",
    "df2[(df2[\"Pclass\"] == 1) & (df2[\"Pclass\"] == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff658a05-2b15-4216-bf82-a86d10d3820f",
   "metadata": {},
   "source": [
    "Ahora veremos métodos que nos ayudarán a filtrar de forma más eficiente en ciertos casos\n",
    "\n",
    "|Método           |Descripción                                                                                                                  |\n",
    "|-----------------|-----------------------------------------------------------------------------------------------------------------------------|\n",
    "|**.isin()**      |Filtra el DataFrame usando los valores de una lista. Es similar a concatenar varios _**\\|**_.                                |\n",
    "|**.between()**   |Filtra el DataFrame usando un intervalo. Es similar a esta expresión _**a <= x <= b**_. Solo funciona con columnas numéricas.|\n",
    "|**.duplicated()**|Muestra los valores duplicados de una columna, omite la primera fila donde aparece ese valor.                                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos sobre la misma columna\n",
    "\n",
    "df2[(df2[\"Pclass\"] == 1) | (df2[\"Pclass\"] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El mismo resultado se puede lograr con: .isin()\n",
    "\n",
    "df2[df2[\"Pclass\"].isin([1, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ba59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede usar con números o cadenas\n",
    "\n",
    "df1[df1[\"Sex\"].isin([\"male\", \"female\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quisieramos filtrar por un rango, podemos usar: .between()\n",
    "# Los dos extremos son incluidos\n",
    "# Solo se puede usar en columnas númericas\n",
    "\n",
    "df1[(df1[\"Age\"].between(28, 30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con ~ podemos obtener el resultado opuesto:\n",
    "\n",
    "df1[~(df1[\"Age\"].between(28, 29))]\n",
    "\n",
    "# En este ejemplo filtramos todos los elementos donde \"Age\" es diferente de 28 y 29, también incluye NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con .duplicated() vemos las filas que tengan valores repetidos, no muestra las primera apariciones\n",
    "\n",
    "df1[df1[\"Age\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81934339",
   "metadata": {},
   "source": [
    "### Cambiar el tipo de datos\n",
    "\n",
    "Por lo general **pandas** utilizará los tipos de datos más generales para crear los **pd.DataFrame()**.\n",
    "\n",
    "Podemos cambiar los tipos de datos de las columnas para ahorrar espacio en memoria o si queremos que los elementos de una columna tengan un comportamiento diferente, como por ejemplo una columna de **enteros** a **strings**.\n",
    "\n",
    "Para esto usamos el método _**.astype()**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af75fc-04fb-48a0-8622-50e726240f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí podemos observar el tipo de dato de cada columna como el especio que ocupa en \"memory usage\"\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos el tipo de dato de la columna \"PassengerId\" a \"int8\"\n",
    "\n",
    "df1[\"PassengerId\"] = df1[\"PassengerId\"].astype(\"int8\")\n",
    "\n",
    "df1.info()\n",
    "\n",
    "# Ahora \"memory usage\" es más bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el tipo de dato de la columna \"Sex\" a \"category\"\n",
    "\n",
    "df1[\"Sex\"] = df1[\"Sex\"].astype(\"category\")\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora la columna \"Sex\" es tipo \"category\"\n",
    "\n",
    "df1[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ee569-bcd4-45ee-84ac-f8ed36289624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# También podemos transformar una columna numérica a string o \"object\"\n",
    "\n",
    "df1[\"PassengerId\"] = df1[\"PassengerId\"].astype(\"str\")\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec717728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar 2 o más a la vez\n",
    "\n",
    "df2[[\"PassengerId\", \"Survived\", \"Pclass\"]] = df2[[\"PassengerId\", \"Survived\", \"Pclass\"]].astype(\"int8\")\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc54136",
   "metadata": {},
   "source": [
    "### Concatenación de DataFrames\n",
    "\n",
    "Al igual que **NumPy** podemos concatenar elementos de 2 dimensiones.\n",
    "\n",
    "Para concatenar usaremos la función _**pd.concat()**_, por defecto esta función usa _**axis = 0**_.\n",
    "\n",
    "Al concatenar **pandas** verificará si comparten el mismo nombre en las columnas y en las filas.\n",
    "\n",
    "En **pandas** no es necesario verificar el número de filas/columnas. Si algún _**pd.DataFrame()**_ no concuerda con otro entonces se llenarán los espacios vacíos con _**NaN's**_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d0d0b",
   "metadata": {},
   "source": [
    "#### Horizontal (axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1876523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Columna_1\" : [\"A\", \"B\"],\n",
    "                    \"Columna_2\" : [\"C\", \"D\"]})\n",
    "\n",
    "df2 = pd.DataFrame({\"Columna_2\" : [\"E\", \"F\", \"G\"],\n",
    "                    \"Columna_4\" : [\"G\", \"H\", \"I\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e527f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para concatenar horizontalmente hay que usar axis = 1\n",
    "\n",
    "# pd.concat() recibe una lista de DataFrames\n",
    "\n",
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando un solo pd.concat() podemos concatenar varios DataFrames a la vez, incluso repetirlos\n",
    "\n",
    "pd.concat([df1, df2, df2, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e19506",
   "metadata": {},
   "source": [
    "### Vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8821ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Columna_1\" : [\"A\", \"B\", \"1\"],\n",
    "                    \"Columna_2\" : [\"C\", \"D\", \"2\"]})\n",
    "\n",
    "df2 = pd.DataFrame({\"Columna_1\" : [\"E\", \"F\"],\n",
    "                    \"Columna_2\" : [\"G\", \"H\"]})\n",
    "\n",
    "# Ambos tienen el mismo nombre en las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e158d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74027519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17175968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como tienen el mismo nombre de columnas, pandas los agrupa automaticamente\n",
    "\n",
    "pd.concat([df1, df2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309de805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este DataFrame solo tiene un nombre de columna en común\n",
    "\n",
    "df3 = pd.DataFrame({\"Columna_1\" : [\"E\", \"F\"],\n",
    "                    \"Columna_3\" : [\"G\", \"H\"]})\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este ejemplo los DataFrames tienen columnas diferentes\n",
    "\n",
    "pd.concat([df1, df3], axis = 0)\n",
    "\n",
    "# Por eso, pandas agrupa la columna en comun, y las que sean diferentes las llena con NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf04b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si nos fijamos, pandas incluso concatena los indices, para evitar este comportamiento podemos agregar otro parametro:\n",
    "# ignore_index = True\n",
    "\n",
    "pd.concat([df1, df3], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8205925",
   "metadata": {},
   "source": [
    "### Merge (join)\n",
    "\n",
    "La operación _**merge**_ (o _join_ en SQL) hace referencia a unir dos **DataFrames** basándose en un conjunto común de columnas, puede ser 1 o más columnas a la vez.\n",
    "\n",
    "En **pandas** tenemos la función _**pd.merge()**_.\n",
    "\n",
    "Para hacer \"merge\" de dos DataFrames es necesario que ambos compartan la misma columna, con el mismo tipo de dato.\n",
    "\n",
    "Parámetro _**how**_:\n",
    "\n",
    "- _inner_: Unión \"interna\", conservando solo las filas que tienen elementos comunes en **ambos DataFrames**.\n",
    "\n",
    "- _left_: Unión \"izquierda\", conservando todas las filas del **DataFrame izquierdo**, incluso si no hay coincidencia en el **DataFrame derecho**, las filas sin coincidencia en el **DataFrame derecho** se rellenan con NaN's.\n",
    "\n",
    "- _right_: Unión \"derecha\", conservando todas las filas del **DataFrame derecho**, incluso si no hay coincidencia en el **DataFrame izquierdo**, las filas sin coincidencia en el **DataFrame izquierdo** se rellenan con NaN's.\n",
    "\n",
    "- _outer_: Unión \"externa\", conservando todas las filas de **ambos DataFrames**. Las filas sin coincidencia en uno de los DataFrames se rellenan con NaN's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0785451-86da-4552-a69c-30f3bb4ba4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usaremos los DataFrames del titanic como ejemplo\n",
    "\n",
    "# Ambos DataFrames comparten la misma columna \"PassengerId\"\n",
    "\n",
    "df1 = pd.read_csv(\"../Data/titanic_1.csv\")\n",
    "df2 = pd.read_csv(\"../Data/titanic_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae200a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge() Une dos DataFrames que tengan una columna en común:\n",
    "# Por defecto \"how\" es \"inner\"\n",
    "\n",
    "df = pd.merge(left = df1, right = df2, left_on = \"PassengerId\", right_on = \"PassengerId\", how = \"inner\")\n",
    "\n",
    "# Guardamos el resultado en df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ac80e-35d6-4bf9-a081-ca7fc919f2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ahora vamos a eliminar algunas filas para ver como funcionan los otros valores del parámetro \"how\"\n",
    "\n",
    "df1 = df1.drop([1, 3, 5], axis = 0)\n",
    "df2 = df2.drop([2, 4, 6], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33360dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how = left\n",
    "# Aquí se mantienen los elementos del DataFrame de la izquierda (df1)\n",
    "# Los espacios vacíos se llenan con NaN's\n",
    "\n",
    "pd.merge(left = df1, right = df2, left_on = \"PassengerId\", right_on = \"PassengerId\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b218f35-6d0c-451e-9a44-552e982371ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how = right\n",
    "# Aquí se mantienen los elementos del DataFrame de la right (df2)\n",
    "# Los espacios vacíos se llenan con NaN's\n",
    "\n",
    "pd.merge(left = df1, right = df2, left_on = \"PassengerId\", right_on = \"PassengerId\", how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a17e0-d27e-4822-a61d-4240070e28c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how = outer\n",
    "# Aquí se mantienen los elementos de ambos DataFrames\n",
    "# Los espacios vacíos se llenan con NaN's\n",
    "\n",
    "pd.merge(left = df1, right = df2, left_on = \"PassengerId\", right_on = \"PassengerId\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5269ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ambos DataFrames comparten el mismo nombre de columna podemos usar el parámetro \"on\"\n",
    "# En lugar de usar \"left_on\" y \"right_on\"\n",
    "\n",
    "pd.merge(left = df1, right = df2, on = \"PassengerId\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484fc77-09d9-4b85-acb0-69415ad46981",
   "metadata": {
    "tags": []
   },
   "source": [
    "### .map() y .apply()\n",
    "\n",
    "Los siguientes métodos se utilizan para transformar una o varias columnas usando una función o un diccionario, también es conocido como \"mapeo\":\n",
    "\n",
    "|Método         |Descripción                                                                          |\n",
    "|---------------|-------------------------------------------------------------------------------------|\n",
    "|**.map()**     |Aplica una función a cada elemento de una o varias columnas de un **pd.DataFrame()**.|\n",
    "|**.apply()**   |Aplica una función a cada fila o columna de un **pd.DataFrame()**.                   |\n",
    "\n",
    "Estos métodos no son **in-place**.\n",
    "\n",
    "Al usar alguno de estos métodos es importante tomar en cuenta si existen NaN's en la columna/fila/DataFrame, ya que algunas operaciones no son compatibles con los NaN's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe75691-77ab-4759-9e27-d45064d394d4",
   "metadata": {},
   "source": [
    "#### .map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6ac64-851c-46ba-8f8d-d39092e60a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series().map()\n",
    "\n",
    "# En este ejemplo usamos la función anónima (lambda) para transformar una pd.Series()\n",
    "\n",
    "df[\"Name\"].map(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19506a31-95f5-4c6b-b5d0-74c7f0ef0044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podemos hacer lo mismo si definimos una función\n",
    "\n",
    "def transformar_lower(x):\n",
    "    return x.lower()\n",
    "\n",
    "df[\"Name\"].map(transformar_lower)\n",
    "\n",
    "# En este caso no es necesario usar la lambda, pero de igual forma se puede hacer\n",
    "\n",
    "# df[\"Name\"].map(lambda x : transformar_lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309ff80-6a00-4ed3-bcf1-5e676756237e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si tenemos un diccionario podemos usarlo para transformar toda la columna\n",
    "\n",
    "dict_sex = {\"male\" : \"H\", \"female\" : \"F\"}\n",
    "\n",
    "df[\"Sex\"].map(dict_sex)\n",
    "\n",
    "# En este caso no es necesario usar la lambda, pero de igual forma se puede hacer\n",
    "\n",
    "# df[\"Name\"].map(lambda x : dict_sex[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fd6b4-4c8b-4b3a-8648-02890c113b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podemos usar operadores ternarios\n",
    "\n",
    "df[\"Age\"].map(lambda x : \"mayor\" if x >= 18 else \"menor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972c395-876f-4c43-bc51-6bbd28aeb13b",
   "metadata": {},
   "source": [
    "#### .apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c6714-1aea-43d4-9da2-541133b41df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .apply() Se puede utilizar para Series y DataFrames\n",
    "\n",
    "# Ejemplo en pd.Series()\n",
    "\n",
    "df[\"Age\"].apply(lambda x : np.sqrt(x))\n",
    "\n",
    "# np.sqrt() toma en cuenta los NaN's, por eso vemos un elemento NaN en la Serie\n",
    "# No todas las funciones se comportan de esta forma\n",
    "\n",
    "# Probar con:\n",
    "# df[\"Age\"].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29470eb4-2b42-480d-8ef4-1e1b51fc8043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejemplo en columnas de pd.DataFrame()\n",
    "\n",
    "df[[\"PassengerId\", \"Age\"]].apply(lambda x : np.sqrt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f76994-4871-4341-a7c5-be054f9d1404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejemplo en filas de pd.DataFrame()\n",
    "\n",
    "df[[\"PassengerId\", \"Age\"]].apply(lambda x : x[\"PassengerId\"] + x[\"Age\"], axis = 1)\n",
    "\n",
    "# Este ejemplo es un poco más complejo\n",
    "# Suma horizontalmente los elementos de cada fila\n",
    "# En lugar de retornar 2 columnas como el ejemplo anterior solo retorna una.\n",
    "# Para hacer uso de los elementos en cada columna usamos la variable \"x\" como si fuese un diccionario\n",
    "# Indicando que debe hacer con cada elemento de cada columna\n",
    "# Usamos axis = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6211f25-ad62-45de-add7-f6fe37acdfc0",
   "metadata": {},
   "source": [
    "### Manipulación de NaN's en pandas.\n",
    "\n",
    "- Encontrar NaN's.\n",
    "- Eliminar NaN's.\n",
    "- Rellenar NaN's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b22653-6a59-414d-b53f-0f82c9908e69",
   "metadata": {},
   "source": [
    "#### Encontrar NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df4eaf-6b24-4909-be56-9f74145dd2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalmente en casi todas las operaciones que hace pandas se omiten los valores nulos (NaN's)\n",
    "# Si quisieramos ver cuantos hay podemos hacer:\n",
    "\n",
    "df[\"Age\"].value_counts()\n",
    "\n",
    "# Aquí pandas está omitiendo los NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c19d31-9f1c-4f45-9af5-7b8527c66238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si agregamos el parámetro \"dropna = False\" ya no omitirá los NaN's\n",
    "\n",
    "df[\"Age\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba980413-5a8e-4bb1-9710-66c80207654e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Con .isnull() podemos filtrar el DataFrame para ver las filas con NaN's de una columna\n",
    "\n",
    "df[df[\"Age\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4228318-6c51-4c8e-abe8-4e70b9a7936f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si queremos ver cuantos NaN's hay por columna podemos usar el método .isna()\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa629996-e011-4bc0-9e18-e757bfffedc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Incluso verlo en porcentaje\n",
    "\n",
    "df.isna().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e82efa-e605-4df6-8eaf-63e91525548e",
   "metadata": {},
   "source": [
    "#### Eliminar NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f011d9-687c-470c-8318-7d85d1eda839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para eliminar los NaN's podemos usar .dropna()\n",
    "# Esta operación no es in-place\n",
    "\n",
    "df.dropna()\n",
    "\n",
    "# El número de filas cambia porque se eliminar las filas con al menos un NaN.\n",
    "# El índice queda igual, no se modifica por haber perdido filas\n",
    "# Para \"actualizar\" el índice podemos usar .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc9ddf-e759-407d-8f2a-fe1d08e746d3",
   "metadata": {},
   "source": [
    "#### Rellenar NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05eb9b-7b08-45e0-8973-6d02e5d5e2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para llenar los NaN's de una columna podemos usar la función .fillna()\n",
    "# El elemento para rellenar los NaN's idealmente debe ser del mismo tipo de dato que la columna\n",
    "# De los contrario pandas transformará todos los elementos al tipo de dato mas general\n",
    "\n",
    "df[\"Age\"].fillna(999)\n",
    "\n",
    "# Probar con:\n",
    "# df[\"Age\"].fillna(\"999\")\n",
    "# Con esto todos los elementos dejan de ser números a ser strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4af76-bfbf-43cc-8589-e71fa429c381",
   "metadata": {},
   "source": [
    "### GroupBy\n",
    "\n",
    "El método _**.groupby()**_ permite agrupar filas de un **pd.DataFrame()** en función de una o más columnas y aplicar funciones a cada grupo.\n",
    "\n",
    "Usaremos en conjunto con el _**.groupby()**_ las funciones de _agregación_ y los métodos _**.aggregate()**_ y _**.agg()**_:\n",
    "\n",
    "|Función   |\n",
    "|----------|\n",
    "|**max**   |\n",
    "|**min**   |\n",
    "|**sum**   |\n",
    "|**mean**  |\n",
    "|**median**|\n",
    "|**count** |\n",
    "|**std**   |\n",
    "\n",
    "Las funciones de _agregación_ se llaman así porque combinan o resumen varios valores en un solo valor.\n",
    "\n",
    "En inglés se les llaman _**aggregate functions**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17adc62-a1f4-4b65-be9f-0e3ed587bbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vamos a usar otro pd.DataFrame()\n",
    "# Este DataFrame contiene información de migración de paises a Canada\n",
    "\n",
    "df = pd.read_excel(\"../Data/Canada.xlsx\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fe18a-d86d-4d7d-95fd-bb2815afd11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Continente\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96433e5-2cde-4a82-8334-6753b2d10627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# .groupby() se usa para agrupar filas que tienen los mismos valores.\n",
    "# Obligatoriamente se usa junto con funciones agregadas para producir informes resumidos.\n",
    "\n",
    "df.groupby(by = \"Continente\")\n",
    "\n",
    "# Solo usar .groupby() retorna el objeto de la operación, pero no muestra nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac892f8-85ce-4ae8-ad68-5f060863b091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para ejecutar alguna operación o aggregate function podemos hacer simplemente:\n",
    "\n",
    "df.groupby(by = \"Continente\").max()\n",
    "\n",
    "# En este ejemplo usamos la función \"max\"\n",
    "# El DataFrame muestra por cada continente el \"max\" por cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b805dd-8294-4395-9864-2b0e0ef99345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# También podemos usar el método .aggregate()\n",
    "\n",
    "df.groupby(by = \"Continente\").aggregate([\"max\"])\n",
    "\n",
    "# En este ejemplo usamos la función \"max\"\n",
    "# El DataFrame muestra por cada continente el \"max\" por cada columna, también añade otro nivel de columnas\n",
    "# Es la principal diferencia entre este método y el anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4493eb-5684-4535-89f3-facfce525723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# El método .aggregate() permite hacer más de una función a la vez\n",
    "\n",
    "df.groupby(by = \"Continente\").aggregate([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48f44e-dca2-4496-b851-943f3ed83c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Otra opción puede ser usar el método .agg()\n",
    "# La diferencia es que este método toma como parámetro un diccionario\n",
    "# Donde la llave es la columna del DataFrame y el valor una lista de aggregate functions\n",
    "\n",
    "df.groupby(by = \"Continente\").agg({2000 : [\"min\", \"max\", \"sum\"],\n",
    "                                   2001 : [\"min\", \"max\"],\n",
    "                                   2002 : [\"count\"]})\n",
    "\n",
    "# La ventaja es que solo aplica las aggregate functions a las columnas indicadas, no a todo el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf62e88-d5fe-4f8a-b5db-0d741dfed505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# También podemos hacer .groupby() a varias columnas a la vez\n",
    "\n",
    "df.groupby(by = [\"Continente\", \"Tipo de region\"]).agg({2000 : [\"min\", \"max\", \"sum\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d229c-37e7-4e1b-a577-6a0c477a44b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# También podemos hacer .groupby() a varias columnas a la vez\n",
    "\n",
    "df.groupby(by = [\"Tipo de region\", \"Continente\"]).agg({2000 : [\"min\", \"max\", \"sum\"]})\n",
    "\n",
    "# En este ejemplo cambiamos el orden de las columnas del .groupby(), el resultado está en otro orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d7fc1-29de-4b7b-be42-661b1829af62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Podemos agregar el parámetro \"as_index = False\" para que las columnas del .groupby()\n",
    "# No se conviertan en el índice\n",
    "\n",
    "df1 = df.groupby(by = [\"Tipo de region\", \"Continente\"], as_index = False).agg({2000 : [\"min\", \"max\", \"sum\"]})\n",
    "\n",
    "df1\n",
    "# De esta manera podemos seguir usando los elementos de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e658c-0477-4c22-b07b-94b76a8b05d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Debido al doble nivel de columnas, obtenemos este resultado al ver las columnas\n",
    "\n",
    "df1.columns\n",
    "\n",
    "# Es una lista de tuplas, donde cada tupla es el nombre de la columna y el aggregate function aplicada a cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567e7c1-c095-494e-8ff1-c0845e9cebbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Para eliminar los niveles de las columnas podemos usar el siguiente código\n",
    "\n",
    "# Guardamos el .groupby() en una variable\n",
    "df1 = df.groupby(by = [\"Tipo de region\", \"Continente\"], as_index = False).agg({2000 : [\"min\", \"max\", \"sum\"]})\n",
    "\n",
    "df1.columns = [f\"{x[0]}_{x[1]}\" if x[1] != \"\" else f\"{x[0]}\" for x in df1.columns.values]\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
